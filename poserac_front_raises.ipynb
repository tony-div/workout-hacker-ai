{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PoseRAC: Front Raises Skeleton Extraction\n",
    "This notebook extracts skeleton data (33 landmarks and 5 average joint angles) as required by the [PoseRAC](https://github.com/MiracleDance/PoseRAC) paper: *Pose Saliency Transformer for Repetitive Action Counting*.\n",
    "\n",
    "## 1. Setup Environment\n",
    "Cloning the repository and installing dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 0. Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1. Environment Setup\n",
    "!git clone https://github.com/MiracleDance/PoseRAC.git\n",
    "!pip install mediapipe yt-dlp opencv-python numpy pandas matplotlib tqdm\n",
    "!mkdir -p models\n",
    "# Download MediaPipe model if not exists\n",
    "import os\n",
    "import requests\n",
    "\n",
    "model_url = \"https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_heavy/float16/1/pose_landmarker_heavy.task\"\n",
    "model_path = \"models/pose_landmarker.task\"\n",
    "if not os.path.exists(model_path):\n",
    "    print(f\"Downloading {model_path}...\")\n",
    "    r = requests.get(model_url)\n",
    "    with open(model_path, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    print(\"Download complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1.1 RepCount_pose Dataset Configuration\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Set path to the RepCount_pose folder on your Google Drive\n",
    "repcount_pose_path = \"/content/drive/MyDrive/RepCount_pose\" # @param {type:\"string\"}\n",
    "annotations_dir = os.path.join(repcount_pose_path, \"annotation\")\n",
    "extracted_poses_dir = os.path.join(repcount_pose_path, \"test_poses_5_ave\")\n",
    "\n",
    "# Load annotations and filter for 'front_raise'\n",
    "def get_front_raise_records(split=\"test\"):\n",
    "    csv_path = os.path.join(annotations_dir, f\"{split}.csv\")\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"Annotation file not found: {csv_path}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    # Filter for 'front_raise' or similar category\n",
    "    front_raise_df = df[df['type'].str.contains('front_raise', case=False, na=False)]\n",
    "    print(f\"Found {len(front_raise_df)} 'front_raise' records in {split} set.\")\n",
    "    return front_raise_df\n",
    "\n",
    "# Example: Get test set front raise videos\n",
    "front_raise_test_df = get_front_raise_records(\"test\")\n",
    "if not front_raise_test_df.empty:\n",
    "    display(front_raise_test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1.2 Load Pre-extracted PoseRAC Data (.npy)\n",
    "import numpy as np\n",
    "\n",
    "def load_repcount_poserac_data(video_id, dataset_dir=extracted_poses_dir):\n",
    "    \"\"\"Loads 33*3 landmarks + 5 angles from the pre-extracted .npy files.\"\"\"\n",
    "    npy_path = os.path.join(dataset_dir, f\"{video_id}.npy\")\n",
    "    if os.path.exists(npy_path):\n",
    "        data = np.load(npy_path)\n",
    "        print(f\"Loaded {data.shape} data for {video_id}\")\n",
    "        # PoseRAC data shape: (num_frames, 104) where 104 = 33*3 (landmarks) + 5 (angles)\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"Data for video {video_id} not found at {npy_path}\")\n",
    "        return None\n",
    "\n",
    "# Test loading the first front raise video data\n",
    "if not front_raise_test_df.empty:\n",
    "    first_video_id = front_raise_test_df.iloc[0]['name']\n",
    "    test_data = load_repcount_poserac_data(first_video_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 2. Imports and PoseRAC Angle Logic\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import json\n",
    "import subprocess\n",
    "import copy\n",
    "from google.colab import files\n",
    "from IPython.display import HTML, display\n",
    "from base64 import b64encode\n",
    "import yt_dlp\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"Calculates the angle at point B (A-B-C) in 3D space.\"\"\"\n",
    "    a = np.array([a['x'], a['y'], a['z']])\n",
    "    b = np.array([b['x'], b['y'], b['z']])\n",
    "    c = np.array([c['x'], c['y'], c['z']])\n",
    "    \n",
    "    v1 = a - b\n",
    "    v2 = c - b\n",
    "    \n",
    "    # Cosine of the angle\n",
    "    dot = np.dot(v1, v2)\n",
    "    norm1 = np.linalg.norm(v1)\n",
    "    norm2 = np.linalg.norm(v2)\n",
    "    \n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0.0\n",
    "        \n",
    "    cosine = dot / (norm1 * norm2)\n",
    "    cosine = np.clip(cosine, -1.0, 1.0)\n",
    "    angle = np.arccos(cosine)\n",
    "    return np.degrees(angle)\n",
    "\n",
    "def get_poserac_angles(landmarks):\n",
    "    \"\"\"Calculates the 5 average joint angles as specified in PoseRAC.\"\"\"\n",
    "    if not landmarks or len(landmarks) < 33:\n",
    "        return [0.0] * 5\n",
    "\n",
    "    # Landmarks indices (MediaPipe)\n",
    "    # L_SHOULDER: 11, R_SHOULDER: 12\n",
    "    # L_ELBOW: 13, R_ELBOW: 14\n",
    "    # L_WRIST: 15, R_WRIST: 16\n",
    "    # L_HIP: 23, R_HIP: 24\n",
    "    # L_KNEE: 25, R_KNEE: 26\n",
    "    # L_ANKLE: 27, R_ANKLE: 28\n",
    "    # L_FOOT_INDEX: 31, R_FOOT_INDEX: 32\n",
    "\n",
    "    # 1. Elbow (Shoulder-Elbow-Wrist)\n",
    "    angle_elbow_l = calculate_angle(landmarks[11], landmarks[13], landmarks[15])\n",
    "    angle_elbow_r = calculate_angle(landmarks[12], landmarks[14], landmarks[16])\n",
    "    avg_elbow = (angle_elbow_l + angle_elbow_r) / 2.0\n",
    "\n",
    "    # 2. Shoulder (Hip-Shoulder-Elbow)\n",
    "    angle_shoulder_l = calculate_angle(landmarks[23], landmarks[11], landmarks[13])\n",
    "    angle_shoulder_r = calculate_angle(landmarks[24], landmarks[12], landmarks[14])\n",
    "    avg_shoulder = (angle_shoulder_l + angle_shoulder_r) / 2.0\n",
    "\n",
    "    # 3. Hip (Shoulder-Hip-Knee)\n",
    "    angle_hip_l = calculate_angle(landmarks[11], landmarks[23], landmarks[25])\n",
    "    angle_hip_r = calculate_angle(landmarks[12], landmarks[24], landmarks[26])\n",
    "    avg_hip = (angle_hip_l + angle_hip_r) / 2.0\n",
    "\n",
    "    # 4. Knee (Hip-Knee-Ankle)\n",
    "    angle_knee_l = calculate_angle(landmarks[23], landmarks[25], landmarks[27])\n",
    "    angle_knee_r = calculate_angle(landmarks[24], landmarks[26], landmarks[28])\n",
    "    avg_knee = (angle_knee_l + angle_knee_r) / 2.0\n",
    "\n",
    "    # 5. Ankle (Knee-Ankle-Foot Index)\n",
    "    angle_ankle_l = calculate_angle(landmarks[25], landmarks[27], landmarks[31])\n",
    "    angle_ankle_r = calculate_angle(landmarks[26], landmarks[28], landmarks[32])\n",
    "    avg_ankle = (angle_ankle_l + angle_ankle_r) / 2.0\n",
    "\n",
    "    return [avg_elbow, avg_shoulder, avg_hip, avg_knee, avg_ankle]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3. Extraction Logic and Front Raise Processing\n",
    "def process_video_poserac(video_path, start_frame=0, end_frame=None, use_gpu=False):\n",
    "    \"\"\"Processes video and extracts PoseRAC format skeleton data (33*3 landmarks + 5 angles).\"\"\"\n",
    "    BaseOptions = mp.tasks.BaseOptions\n",
    "    PoseLandmarker = mp.tasks.vision.PoseLandmarker\n",
    "    PoseLandmarkerOptions = mp.tasks.vision.PoseLandmarkerOptions\n",
    "    VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "    options = PoseLandmarkerOptions(\n",
    "        base_options=BaseOptions(\n",
    "            model_asset_path='models/pose_landmarker.task',\n",
    "            delegate=BaseOptions.Delegate.GPU if use_gpu else BaseOptions.Delegate.CPU\n",
    "        ),\n",
    "        running_mode=VisionRunningMode.VIDEO\n",
    "    )\n",
    "\n",
    "    poserac_data = []\n",
    "    with PoseLandmarker.create_from_options(options) as landmarker:\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        if fps <= 0: fps = 30.0\n",
    "\n",
    "        if end_frame is None or end_frame <= 0: end_frame = total_frames\n",
    "        start_frame, end_frame = max(0, int(start_frame)), min(total_frames, int(end_frame))\n",
    "        \n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "        frame_count = start_frame\n",
    "        pbar = tqdm(total=end_frame - start_frame, desc=\"Processing PoseRAC Skeleton\", leave=False)\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret or frame_count >= end_frame: break\n",
    "\n",
    "            timestamp_ms = int((frame_count / fps) * 1000)\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
    "\n",
    "            detection_result = landmarker.detect_for_video(mp_image, timestamp_ms)\n",
    "\n",
    "            frame_landmarks = []\n",
    "            if detection_result.pose_landmarks:\n",
    "                for landmark in detection_result.pose_landmarks[0]:\n",
    "                    frame_landmarks.append({'x': landmark.x, 'y': landmark.y, 'z': landmark.z, 'visibility': landmark.visibility})\n",
    "\n",
    "            if len(frame_landmarks) == 33:\n",
    "                angles = get_poserac_angles(frame_landmarks)\n",
    "                # Combine 33*3 landmarks + 5 angles = 104 values (or 33*4 if including visibility)\n",
    "                # PoseRAC typically uses 3D coordinates.\n",
    "                poserac_data.append({\n",
    "                    'frame': frame_count,\n",
    "                    'timestamp': timestamp_ms,\n",
    "                    'landmarks': frame_landmarks,\n",
    "                    'poserac_angles': angles\n",
    "                })\n",
    "\n",
    "            frame_count += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "        pbar.close()\n",
    "        cap.release()\n",
    "    return poserac_data\n",
    "\n",
    "def save_poserac_data(data, output_file):\n",
    "    \"\"\"Saves PoseRAC data in JSON format.\"\"\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(f\"PoseRAC data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 4. Choose Input Source\n",
    "input_source = \"RepCount_pose Dataset\" # @param [\"Upload Video (Local)\", \"YouTube URL\", \"Google Drive\", \"RepCount_pose Dataset\"]\n",
    "# For RepCount_pose, specify the video name/ID (e.g., 'front_raise_001')\n",
    "repcount_video_id = \"front_raise_001\" # @param {type:\"string\"}\n",
    "youtube_url = \"https://www.youtube.com/watch?v=-t7fuZ0KhDA\" # @param {type:\"string\"}\n",
    "drive_file_path = \"\" # @param {type:\"string\"}\n",
    "frame_ranges_str = \"0-500\" # @param {type:\"string\"}\n",
    "use_gpu = True # @param {type:\"boolean\"}\n",
    "\n",
    "source_path = \"\"\n",
    "input_filename = \"front_raises.mp4\"\n",
    "is_repcount = False\n",
    "\n",
    "if input_source == \"RepCount_pose Dataset\":\n",
    "    # Try to find the video file in raw_videos_dir (if provided) or just load the .npy\n",
    "    raw_videos_dir = os.path.join(repcount_pose_path, \"original_data\", \"videos\")\n",
    "    # Video extension might be .mp4, .avi, etc.\n",
    "    source_path = os.path.join(raw_videos_dir, f\"{repcount_video_id}.mp4\")\n",
    "    if not os.path.exists(source_path):\n",
    "        # Check for other extensions\n",
    "        for ext in ['.avi', '.MP4', '.mov']:\n",
    "            if os.path.exists(os.path.join(raw_videos_dir, f\"{repcount_video_id}{ext}\")):\n",
    "                source_path = os.path.join(raw_videos_dir, f\"{repcount_video_id}{ext}\")\n",
    "                break\n",
    "    \n",
    "    if os.path.exists(source_path):\n",
    "        print(f\"Using RepCount video: {source_path}\")\n",
    "    else:\n",
    "        print(f\"Warning: Video file for {repcount_video_id} not found at {raw_videos_dir}. Extraction will require raw video.\")\n",
    "    \n",
    "    is_repcount = True\n",
    "    input_filename = f\"{repcount_video_id}.mp4\"\n",
    "\n",
    "elif input_source == \"Upload Video (Local)\":\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    if uploaded:\n",
    "        source_path = list(uploaded.keys())[0]\n",
    "        input_filename = source_path\n",
    "        print(f\"Uploaded {source_path}\")\n",
    "\n",
    "elif input_source == \"YouTube URL\":\n",
    "    if youtube_url:\n",
    "        print(\"Downloading YouTube video...\")\n",
    "        ydl_opts = {'format': 'best[ext=mp4]/best', 'outtmpl': 'input_video.mp4', 'noplaylist': True}\n",
    "        try:\n",
    "            with yt_dlp.YoutubeDL(ydl_opts) as ydl: ydl.download([youtube_url])\n",
    "            source_path = 'input_video.mp4'; input_filename = 'front_raises.mp4'\n",
    "        except Exception as e: print(f\"Error downloading YouTube video: {e}\")\n",
    "\n",
    "elif input_source == \"Google Drive\":\n",
    "    if drive_file_path and os.path.exists(drive_file_path):\n",
    "        source_path = drive_file_path\n",
    "        input_filename = os.path.basename(drive_file_path)\n",
    "    else:\n",
    "        print(f\"Drive file not found: {drive_file_path}\")\n",
    "\n",
    "if source_path:\n",
    "    print(f\"Ready to process: {source_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 5. Run Extraction & Save Data\n",
    "output_json = \"poserac_front_raises.json\"\n",
    "all_poserac_data = []\n",
    "\n",
    "# If RepCount dataset is used, we can load the pre-extracted data if it exists\n",
    "if input_source == \"RepCount_pose Dataset\":\n",
    "    npy_data = load_repcount_poserac_data(repcount_video_id)\n",
    "    if npy_data is not None:\n",
    "        print(f\"Using pre-extracted data for {repcount_video_id}. No extraction needed.\")\n",
    "        # Convert npy (frames, 104) back to our list of dicts format for visualization consistency\n",
    "        for i, row in enumerate(npy_data):\n",
    "            # landmarks: row[0:99] (33*3), angles: row[99:104] (5)\n",
    "            all_poserac_data.append({\n",
    "                'frame': i,\n",
    "                'poserac_angles': row[99:104].tolist()\n",
    "            })\n",
    "    elif os.path.exists(source_path):\n",
    "        print(f\"Data not found, running extraction on {source_path}...\")\n",
    "        all_poserac_data = process_video_poserac(source_path, use_gpu=use_gpu)\n",
    "else:\n",
    "    # Handle other sources with potential frame ranges\n",
    "    frame_ranges = []\n",
    "    try:\n",
    "        for r in frame_ranges_str.split(','):\n",
    "            start, end = map(int, r.strip().split('-'))\n",
    "            frame_ranges.append((start, end))\n",
    "    except: frame_ranges = [(0, 1000)]\n",
    "    \n",
    "    for start, end in frame_ranges:\n",
    "        print(f\"Processing range {start}-{end}...\")\n",
    "        range_data = process_video_poserac(source_path, start_frame=start, end_frame=end, use_gpu=use_gpu)\n",
    "        all_poserac_data.extend(range_data)\n",
    "\n",
    "if all_poserac_data:\n",
    "    save_poserac_data(all_poserac_data, output_json)\n",
    "    files.download(output_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 6. Visualize Results (Front Raises Analysis)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if all_poserac_data:\n",
    "    frames = [d['frame'] for d in all_poserac_data]\n",
    "    elbow_angles = [d['poserac_angles'][0] for d in all_poserac_data]\n",
    "    shoulder_angles = [d['poserac_angles'][1] for d in all_poserac_data]\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(frames, shoulder_angles, label='Shoulder Angle (Hip-Shoulder-Elbow)', color='blue')\n",
    "    plt.plot(frames, elbow_angles, label='Elbow Angle (Shoulder-Elbow-Wrist)', color='green')\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('Angle (Degrees)')\n",
    "    plt.title('PoseRAC Angles: Front Raises Analysis')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Peak Shoulder angle identifies the top of the raise\n",
    "    peak_frames = [f for f, s in zip(frames, shoulder_angles) if s > 120]\n",
    "    print(f\"Identified {len(peak_frames)} potential frames at peak contraction.\")\n",
    "else:\n",
    "    print(\"No data processed yet. Please run Cell 5.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 7. Integrating with PoseRAC Model\n",
    "# This cell explains how to use the extracted data with the cloned PoseRAC repo.\n",
    "# PoseRAC expects a specific folder structure and salient pose annotations.\n",
    "\n",
    "print(\"--- Integration with PoseRAC ---\")\n",
    "print(\"1. Locate 'PoseRAC' folder created in Cell 1.\")\n",
    "print(\"2. Use the 'pre_train_angles.py' script if you have many videos.\")\n",
    "print(\"3. For front raises specifically, ensure your 'poserac_front_raises.json' contains sequences corresponding to single repetitions or clear sets.\")\n",
    "print(\"4. The 5 angles (Elbow, Shoulder, Hip, Knee, Ankle) are now calculated and ready.\")\n",
    "\n",
    "# Example: Check if the cloned repo has some specific utility we can use\n",
    "try:\n",
    "    import sys\n",
    "    sys.path.append('PoseRAC')\n",
    "    # If there are specific utilities, we could import them here.\n",
    "    print(\"PoseRAC path added to sys.path.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not find PoseRAC utilities: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
